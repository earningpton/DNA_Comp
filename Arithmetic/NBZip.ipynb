{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is sklearn Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.46674471 0.53325529]]\n",
      "(1000, 4)\n",
      "(1000,)\n",
      "[[0.46674471 0.53325529]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.predict_proba([[0, 0, 0, 0]]))\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "clf_pf = GaussianNB()\n",
    "clf_pf.partial_fit(X, y, np.unique(y))\n",
    "clf_pf.partial_fit(X, y, np.unique(y))\n",
    "print(clf_pf.predict_proba([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4638690\n"
     ]
    }
   ],
   "source": [
    "list_of_lists = []\n",
    "with open('data\\ecoli\\Ecoli.txt') as f:\n",
    "    for line in f:\n",
    "        #inner_list = [elt.strip() for elt in line.split()]\n",
    "        inner_list = list(line)\n",
    "        list_of_lists.append(inner_list)\n",
    "print(len(list_of_lists[0])) # About 4 MB\n",
    "ecoli = list_of_lists[0]\n",
    "\n",
    "import arithc as arith\n",
    "import fqt, ppm\n",
    "import contextlib, sys\n",
    "import filecmp\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from plist import ProbabilityList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 103, 99, 116]\n",
      "4638690\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "s = ecoli\n",
    "char_list = [97, 103, 99, 116] # we can read this as we go\n",
    "print(char_list)\n",
    "update_period = len(s)\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "legend = dict([(v, k) for k, v in enumerate(char_list)]) # map character to 0,1,2,3,4, etc.\n",
    "\n",
    "temp_dict = {'a':97,'g': 103,'c': 99,'t': 116}\n",
    "s = [temp_dict[i] for i in s]\n",
    "#Train model\n",
    "x = np.zeros((update_period-64, 64)) # 64 characters context\n",
    "y = np.zeros((update_period-64))\n",
    "\n",
    "print(len(s))\n",
    "idx3 = 0\n",
    "for idx2 in range(64,len(s)):\n",
    "    train_seq = [legend[i] for i in s[idx2-64:idx2]] \n",
    "    train_target = legend[s[idx2]]\n",
    "    x[idx3,:] = np.array(train_seq)\n",
    "    y[idx3] = train_target\n",
    "    idx3 += 1\n",
    "predicted_onehot = []\n",
    "for i in range(len(ecoli)//100000 - 1):\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "    clf.partial_fit(x[100000*i:100000*(i+1)], y[100000*i:100000*(i+1)], np.unique(y))\n",
    "\n",
    "    predicted_onehot += list(clf.predict_proba(x[100000*(i+1):100000*(i+2)]))\n",
    "predicted_onehot += list(clf.predict_proba(x[100000*(len(ecoli)//100000):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25821662, 0.25187857, 0.20216415, 0.28774067])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_onehot[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100064"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)-len(predicted_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 percent done\n"
     ]
    }
   ],
   "source": [
    "char_list = [97, 103, 99, 116]\n",
    "def RF_Warmcompress(inp, bitout):\n",
    "    initprobs= [1/257 for i in range(257)]\n",
    "    initprobs[256] = 1-sum(initprobs[:256])\n",
    "    model = ProbabilityList(initprobs) # For the first 200,000\n",
    "    enc = arith.ArithmeticCoder(32)\n",
    "    enc.start_encode(bitout) # New line!\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        symbol = inp.read(1)\n",
    "        if len(symbol) == 0:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "        ## Progress Evaluation ## only internal\n",
    "        if idx % (len(ecoli)//10) == 0:\n",
    "            print(str(10*idx//(len(ecoli)//10)) + ' percent done')\n",
    "            clear_output(wait = True)\n",
    "        if idx == 100065:\n",
    "            model = ProbabilityList(initprobs) # reset the model\n",
    "        if idx >= 100065:\n",
    "            for val, prob in enumerate(predicted_onehot[idx-100065]):\n",
    "                model.set_prob(char_list[val], prob+1/257)\n",
    "            model.set_prob(256, 1/25700)\n",
    "            model.normalize()\n",
    "            \n",
    "        t = 2**16 ## New lines!\n",
    "        l = int(model.get_low(symbol[0])*2**16)\n",
    "        h = int(model.get_high(symbol[0])*2**16)\n",
    "        enc.storeRegion(l,h,t) \n",
    "        \n",
    "        if idx < 100065: # back up before LSTM model\n",
    "            model.prob_list[symbol[0]] += 1/257\n",
    "            model.normalize()\n",
    "    t = 2**16 ## New lines!\n",
    "    l = int(model.get_low(256)*2**16)\n",
    "    h = int(model.get_high(256)*2**16)\n",
    "    enc.storeRegion(l,h,t)\n",
    "    enc.finish_encode(bitout)  # New line!\n",
    "inputfile, outputfile = 'data\\ecoli\\Ecoli.txt', 'data\\ecoli\\Ecoli_NB64.txt'\n",
    "\n",
    "#Perform file compression\n",
    "with open(inputfile, \"rb\") as inp, \\\n",
    "        contextlib.closing(arith.BitOutputStream(open(outputfile, \"wb\"))) as bitout:\n",
    "    RF_Warmcompress(inp, bitout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 percent done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "char_list = [97, 103, 99, 116]\n",
    "def RF_Warmcompress(inp, bitout):\n",
    "    initfreqs = fqt.FlatFrequencyTable(257)\n",
    "    model = fqt.SimpleFrequencyTable(initfreqs) # For the first 200,000\n",
    "    enc = arith.ArithmeticCoder(32)\n",
    "    enc.start_encode(bitout) # New line!\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        symbol = inp.read(1)\n",
    "        if len(symbol) == 0:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        ## Progress Evaluation ## only internal\n",
    "        if idx % (len(ecoli)//10) == 0:\n",
    "            print(str(10*idx//(len(ecoli)//10)) + ' percent done')\n",
    "            clear_output(wait = True)\n",
    "        if idx == 100065:\n",
    "            initfreqs = fqt.FlatFrequencyTable(257)\n",
    "            model = fqt.SimpleFrequencyTable(initfreqs) # reset the model\n",
    "        if idx >= 100065:\n",
    "            for val, prob in enumerate(predicted_onehot[idx-100065]):\n",
    "                model.set(char_list[val], int(prob*100000)+1)\n",
    "            \n",
    "        t = model.get_total() ## New lines!\n",
    "        l = model.get_low(symbol[0])\n",
    "        h = model.get_high(symbol[0])\n",
    "        enc.storeRegion(l,h,t) \n",
    "        \n",
    "        if idx < 100065: # back up before LSTM model\n",
    "            model.increment(symbol[0])\n",
    "    t = model.get_total() ## New lines!\n",
    "    l = model.get_low(256)\n",
    "    h = model.get_high(256)\n",
    "    enc.storeRegion(l,h,t)\n",
    "    enc.finish_encode(bitout)  # New line!\n",
    "inputfile, outputfile = 'data\\ecoli\\Ecoli.txt', 'data\\ecoli\\Ecoli_NB.txt'\n",
    "\n",
    "#Perform file compression\n",
    "with open(inputfile, \"rb\") as inp, \\\n",
    "        contextlib.closing(arith.BitOutputStream(open(outputfile, \"wb\"))) as bitout:\n",
    "    RF_Warmcompress(inp, bitout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 103, 99, 116]\n",
      "4638690\n",
      "0\n",
      "400\n",
      "800\n",
      "1200\n",
      "1600\n",
      "2000\n",
      "2400\n",
      "2800\n",
      "3200\n",
      "3600\n",
      "4000\n",
      "4400\n",
      "4800\n",
      "5200\n",
      "5600\n",
      "6000\n",
      "6400\n",
      "6800\n",
      "7200\n",
      "7600\n",
      "8000\n",
      "8400\n",
      "8800\n",
      "9200\n",
      "9600\n",
      "10000\n",
      "10400\n",
      "10800\n",
      "11200\n",
      "11600\n",
      "12000\n",
      "12400\n",
      "12800\n",
      "13200\n",
      "13600\n",
      "14000\n",
      "14400\n",
      "14800\n",
      "15200\n",
      "15600\n",
      "16000\n",
      "16400\n",
      "16800\n",
      "17200\n",
      "17600\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "s = ecoli\n",
    "char_list = [97, 103, 99, 116] # we can read this as we go\n",
    "print(char_list)\n",
    "update_period = len(s)\n",
    "\n",
    "clf = GaussianNB()\n",
    "k = 6\n",
    "n = 256\n",
    "legend = dict([(v, k) for k, v in enumerate(char_list)]) # map character to 0,1,2,3,4, etc.\n",
    "\n",
    "temp_dict = {'a':97,'g': 103,'c': 99,'t': 116}\n",
    "s = [temp_dict[i] for i in s]\n",
    "#Train model\n",
    "x = np.zeros((update_period-k, k)) # 64 characters context\n",
    "y = np.zeros((update_period-k))\n",
    "\n",
    "print(len(s))\n",
    "idx3 = 0\n",
    "for idx2 in range(k,len(s)):\n",
    "    train_seq = [legend[i] for i in s[idx2-k:idx2]] \n",
    "    train_target = legend[s[idx2]]\n",
    "    x[idx3,:] = np.array(train_seq)\n",
    "    y[idx3] = train_target\n",
    "    idx3 += 1\n",
    "predicted_onehot = []\n",
    "for i in range(len(ecoli)//n - 1):\n",
    "    if i%400 == 0:\n",
    "        print(i)\n",
    "    clf.partial_fit(x[n*i:n*(i+1)], y[n*i:n*(i+1)], np.unique(y))\n",
    "\n",
    "    predicted_onehot += list(clf.predict_proba(x[n*(i+1):n*(i+2)]))\n",
    "predicted_onehot += list(clf.predict_proba(x[n*(len(ecoli)//n):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "256+6+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 percent done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "char_list = [97, 103, 99, 116]\n",
    "def RF_Warmcompress(inp, bitout):\n",
    "    initfreqs = fqt.FlatFrequencyTable(257)\n",
    "    model = fqt.SimpleFrequencyTable(initfreqs) # For the first 200,000\n",
    "    enc = arith.ArithmeticCoder(32)\n",
    "    enc.start_encode(bitout) # New line!\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        symbol = inp.read(1)\n",
    "        if len(symbol) == 0:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        ## Progress Evaluation ## only internal\n",
    "        if idx % (len(ecoli)//10) == 0:\n",
    "            print(str(10*idx//(len(ecoli)//10)) + ' percent done')\n",
    "            clear_output(wait = True)\n",
    "        if idx == 263:\n",
    "            initfreqs = fqt.FlatFrequencyTable(257)\n",
    "            model = fqt.SimpleFrequencyTable(initfreqs) # reset the model\n",
    "        if idx >= 263:\n",
    "            for val, prob in enumerate(predicted_onehot[idx-263]):\n",
    "                model.set(char_list[val], int(prob*100000)+1)\n",
    "            \n",
    "        t = model.get_total() ## New lines!\n",
    "        l = model.get_low(symbol[0])\n",
    "        h = model.get_high(symbol[0])\n",
    "        enc.storeRegion(l,h,t) \n",
    "        \n",
    "        if idx < 263: # back up before LSTM model\n",
    "            model.increment(symbol[0])\n",
    "    t = model.get_total() ## New lines!\n",
    "    l = model.get_low(256)\n",
    "    h = model.get_high(256)\n",
    "    enc.storeRegion(l,h,t)\n",
    "    enc.finish_encode(bitout)  # New line!\n",
    "inputfile, outputfile = 'data\\ecoli\\Ecoli.txt', 'data\\ecoli\\Ecoli_NB6_256.txt'\n",
    "\n",
    "#Perform file compression\n",
    "with open(inputfile, \"rb\") as inp, \\\n",
    "        contextlib.closing(arith.BitOutputStream(open(outputfile, \"wb\"))) as bitout:\n",
    "    RF_Warmcompress(inp, bitout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try cheating to confirm that we are not crazy:\n",
    "Say we know the correct answer with 90% certainty we want to show that the compression ratio is incredible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cheat_code = [[0.9,0.033,0.033,0.034],[0.033,0.9,0.033,0.034],[0.033,0.033,0.9,0.034],[0.033,0.033,0.034,0.9]]\n",
    "predicted_toohot = [np.array(cheat_code[int(i)]) for i in list(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ecoli)-len(predicted_toohot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 2., 0., 3., 3., 2., 3., 1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 0, 3, 3, 2, 3, 1, 0, 2, 3, 1, 2, 0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[legend[temp_dict[i]] for i in ecoli[6:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.033, 0.033, 0.034, 0.9  ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_toohot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 percent done\n"
     ]
    }
   ],
   "source": [
    "char_list = [97, 103, 99, 116]\n",
    "def Cheatcomp(inp, bitout):\n",
    "    initfreqs = fqt.FlatFrequencyTable(257)\n",
    "    model = fqt.SimpleFrequencyTable(initfreqs) # For the first 200,000\n",
    "    enc = arith.ArithmeticCoder(32)\n",
    "    enc.start_encode(bitout) # New line!\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        symbol = inp.read(1)\n",
    "        if len(symbol) == 0:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        ## Progress Evaluation ## only internal\n",
    "        if idx % (len(ecoli)//10) == 0:\n",
    "            print(str(10*idx//(len(ecoli)//10)) + ' percent done')\n",
    "            clear_output(wait = True)\n",
    "        if idx == 7:\n",
    "            initfreqs = fqt.FlatFrequencyTable(257)\n",
    "            model = fqt.SimpleFrequencyTable(initfreqs) # reset the model\n",
    "        if idx >= 7:\n",
    "            for val, prob in enumerate(predicted_toohot[idx-7]):\n",
    "                model.set(char_list[val], int(prob*100000)+1)\n",
    "            \n",
    "        t = model.get_total() ## New lines!\n",
    "        l = model.get_low(symbol[0])\n",
    "        h = model.get_high(symbol[0])\n",
    "        enc.storeRegion(l,h,t) \n",
    "        \n",
    "        if idx < 7: # back up before LSTM model\n",
    "            model.increment(symbol[0])\n",
    "    t = model.get_total() ## New lines!\n",
    "    l = model.get_low(256)\n",
    "    h = model.get_high(256)\n",
    "    enc.storeRegion(l,h,t)\n",
    "    enc.finish_encode(bitout)  # New line!\n",
    "inputfile, outputfile = 'data\\ecoli\\Ecoli.txt', 'data\\ecoli\\Ecoli_cheat_real.txt'\n",
    "\n",
    "#Perform file compression\n",
    "with open(inputfile, \"rb\") as inp, \\\n",
    "        contextlib.closing(arith.BitOutputStream(open(outputfile, \"wb\"))) as bitout:\n",
    "    Cheatcomp(inp, bitout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
