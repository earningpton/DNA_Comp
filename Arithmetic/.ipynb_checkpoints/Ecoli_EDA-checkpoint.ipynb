{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do Exploratory Data Analysis for E.Coli by comparing it to fake ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = []\n",
    "with open('data\\ecoli\\Ecoli.txt') as f:\n",
    "    for line in f:\n",
    "        #inner_list = [elt.strip() for elt in line.split()]\n",
    "        inner_list = list(line)\n",
    "        list_of_lists.append(inner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4638690\n"
     ]
    }
   ],
   "source": [
    "# There is only 1 line\n",
    "print(len(list_of_lists[0])) # About 4 MB\n",
    "ecoli = list_of_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\ecoli\\Fake_Ecoli.txt') as f:\n",
    "    for line in f:\n",
    "        #inner_list = [elt.strip() for elt in line.split()]\n",
    "        fecoli = list(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'c': 1179222, 'g': 1176575, 'a': 1142069, 't': 1140824})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(ecoli)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'c': 1178622, 'g': 1178186, 'a': 1141315, 't': 1140567})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(fecoli)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is preference in nature, as exhbited by the order of 2 in Ecoli vs Fake Ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gc': 383734, 'cg': 346554, 'tt': 339460, 'aa': 337820, 'ca': 325090, 'tg': 322170, 'at': 309781, 'cc': 271591, 'gg': 270025, 'tc': 267255, 'ga': 267219, 'ac': 256642, 'gt': 255597, 'ag': 237826, 'ct': 235986, 'ta': 211939})\n"
     ]
    }
   ],
   "source": [
    "ecoli_2 = [ecoli[i]+ecoli[i+1] for i in range(len(ecoli)-1)]\n",
    "counter=collections.Counter(ecoli_2)\n",
    "print(counter)\n",
    "# there are 4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'cc': 299846, 'gg': 299710, 'cg': 298861, 'gc': 298814, 'ca': 290554, 'ag': 290467, 'tc': 290147, 'gt': 289896, 'ac': 289815, 'ga': 289766, 'ct': 289361, 'tg': 289148, 'tt': 281082, 'aa': 280804, 'at': 280228, 'ta': 280190})\n"
     ]
    }
   ],
   "source": [
    "fecoli_2 = [fecoli[i]+fecoli[i+1] for i in range(len(fecoli)-1)]\n",
    "counter=collections.Counter(fecoli_2)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is even stronger preference in nature, as exhbited by the order of 6 in Ecoli vs Fake Ecoli\n",
    "\n",
    "For order of 4, the starkest contrast is the range with 'cagc' and 'gctg' occuring 37000 times as opposed to ctag which only occurs 900 times. The fake ecoli shows a more 'statistical' distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ecoli_4 = [ecoli[i]+ecoli[i+1]+ecoli[i+2]+ecoli[i+3]   for i in range(len(ecoli)-3)]\n",
    "counter=collections.Counter(ecoli_4)\n",
    "#print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fecoli_4 = [fecoli[i]+fecoli[i+1]+fecoli[i+2]+fecoli[i+3]   for i in range(len(fecoli)-3)]\n",
    "counter=collections.Counter(fecoli_4)\n",
    "#print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Three = cgccag : 5392, ctggcg : 5254, gccagc : 4823\n",
      "Bottom Three = tctagg : 19, ctagga : 17, cctagg : 16\n"
     ]
    }
   ],
   "source": [
    "ecoli_6 = [ecoli[i]+ecoli[i+1]+ecoli[i+2]+ecoli[i+3]+ecoli[i+4]+ecoli[i+5]   for i in range(len(ecoli)-5)]\n",
    "counter=collections.Counter(ecoli_6)\n",
    "#print(counter)\n",
    "print('Top Three = cgccag : 5392, ctggcg : 5254, gccagc : 4823')\n",
    "print('Bottom Three = tctagg : 19, ctagga : 17, cctagg : 16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Three = gccccg : 1335, cggggg : 1329, cccgcg : 1328\n",
      "Bottom Three = tcaaaa : 976, ttatat : 962, aaaata : 956\n"
     ]
    }
   ],
   "source": [
    "fecoli_6 = [fecoli[i]+fecoli[i+1]+fecoli[i+2]+fecoli[i+3]+fecoli[i+4]+fecoli[i+5]   for i in range(len(fecoli)-5)]\n",
    "counter=collections.Counter(fecoli_6)\n",
    "#print(counter)\n",
    "print('Top Three = gccccg : 1335, cggggg : 1329, cccgcg : 1328')\n",
    "print('Bottom Three = tcaaaa : 976, ttatat : 962, aaaata : 956')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try bag of word model, to see if it works better for the real file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = {}\n",
    "words = 4\n",
    "\n",
    "words_tokens = ecoli\n",
    "for i in range(len(words_tokens)-words):\n",
    "    seq = ' '.join(words_tokens[i:i+words])\n",
    "    #print(seq)\n",
    "    if  seq not in ngrams.keys():\n",
    "        ngrams[seq] = []\n",
    "    ngrams[seq].append(words_tokens[i+words])\n",
    "curr_sequence = ' '.join(words_tokens[0:words])\n",
    "output = curr_sequence\n",
    "for i in range(3000):\n",
    "    if curr_sequence not in ngrams.keys():\n",
    "        break\n",
    "    possible_words = ngrams[curr_sequence]\n",
    "    next_word = possible_words[random.randrange(len(possible_words))]\n",
    "    output += ' ' + next_word\n",
    "    seq_words = output.split(' ')\n",
    "    curr_sequence = ' '.join(seq_words[len(seq_words)-words:len(seq_words)])\n",
    "\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)\n",
    "temp = ''.join(output.split(' '))\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecoli_4 = [temp[i]+temp[i+1]+temp[i+2]+temp[i+3]   for i in range(len(temp)-3)]\n",
    "counter=collections.Counter(fecoli_4)\n",
    "# #print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try LSTM model:\n",
    "One with update every 100 intervals, every 4 intervals, and then at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Activation\n",
    "# If keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Activation\n",
    "seq_length = 64  #Length of the sequence to be inserted into the LSTM\n",
    "vocab_size = 4  #Size of the final dense layer of the model\n",
    "lstm_cells = 16  #Size of the LSTM layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_cells, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = ['a','t','c','g']\n",
    "legend = dict([(v, k) for k, v in enumerate(vocab)])\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# if keras\n",
    "# from keras.utils import to_categorical\n",
    "to_categorical(legend['a'],num_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "vocab = ['a','t','c','g']\n",
    "legend = dict([(v, k) for k, v in enumerate(vocab)])\n",
    "ecoli_temp = copy.deepcopy(ecoli)\n",
    "pred_list = ecoli_temp[:64]\n",
    "for j in range(64,10000,100):\n",
    "\n",
    "    # At this point, please note that the length of the deque is seq_length + 1.\n",
    "    \n",
    "    # Dictionary to convert numbers to classes:\n",
    "    x = np.zeros((100, 64, 1))\n",
    "    y = np.zeros((100, 4))\n",
    "    \n",
    "    x_pred = np.zeros((100, seq_length, 1))\n",
    "    \n",
    "    for k in range(100):\n",
    "        # Converts the deque into a list:\n",
    "        # Each iteration is comprised of 1 training and 1 prediction. These are the training sequence and target:\n",
    "        train_seq = [legend[i] for i in ecoli_temp[j-64+k:j+k]] \n",
    "        train_target = legend[ecoli_temp[j+k]]\n",
    "        # And the prediction sequence just shifts the window by 1:\n",
    "        pred_seq = [legend[i] for i in ecoli_temp[j-63+99+k:j+1+99+k]]\n",
    "        x_pred[k,:] = np.array(pred_seq).reshape((64,1))\n",
    "        # Batches data into a batch of size 1:\n",
    "        \n",
    "        \n",
    "        x[k,:] = np.array(train_seq).reshape((64,1))\n",
    "        y[k,:] = to_categorical( train_target, num_classes=vocab_size )\n",
    "        # Online training:\n",
    "        model.fit(x=x, y=y, batch_size=32, epochs=1, verbose=0)\n",
    "\n",
    "    # Now that one training step is done, make a prediction:\n",
    "    \n",
    "    predicted_onehot = model.predict(x_pred)\n",
    "    # Avoids \"index out of range\" erros when the LSTM vocab is still being built:\n",
    "    predicted_index = np.argmax(predicted_onehot, axis = 1) #, len(vocab)-1)\n",
    "    predicted_char = [vocab[idx] for idx in predicted_index]\n",
    "    # Reverts deque length to seq_length:\n",
    "    pred_list += predicted_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32114882506527415"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With batch training\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:3064]))\n",
    "984/3064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3086"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With batch training\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:10064]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "vocab = ['a','t','c','g']\n",
    "legend = dict([(v, k) for k, v in enumerate(vocab)])\n",
    "ecoli_temp = copy.deepcopy(ecoli)\n",
    "pred_list = ecoli_temp[:64]\n",
    "for j in range(64,10000):\n",
    "\n",
    "    # At this point, please note that the length of the deque is seq_length + 1.\n",
    "    \n",
    "    # Dictionary to convert numbers to classes:\n",
    "    x = np.zeros((1, 64, 1))\n",
    "    y = np.zeros((1, 4))\n",
    "    \n",
    "    x_pred = np.zeros((1, seq_length, 1))\n",
    "\n",
    "    # Converts the deque into a list:\n",
    "    # Each iteration is comprised of 1 training and 1 prediction. These are the training sequence and target:\n",
    "    train_seq = [legend[i] for i in ecoli_temp[j-64:j]] \n",
    "    train_target = legend[ecoli_temp[j]]\n",
    "    # And the prediction sequence just shifts the window by 1:\n",
    "    pred_seq = [legend[i] for i in ecoli_temp[j-63:j+1]]\n",
    "    x_pred[0,:] = np.array(pred_seq).reshape((64,1))\n",
    "    # Batches data into a batch of size 1:\n",
    "\n",
    "\n",
    "    x[0,:] = np.array(train_seq).reshape((64,1))\n",
    "    y[0,:] = to_categorical( train_target, num_classes=vocab_size )\n",
    "    # Online training:\n",
    "    model.fit(x=x, y=y, batch_size=1, epochs=1, verbose=0)\n",
    "\n",
    "    # Now that one training step is done, make a prediction:\n",
    "    \n",
    "    predicted_onehot = model.predict(x_pred)\n",
    "    # Avoids \"index out of range\" erros when the LSTM vocab is still being built:\n",
    "    predicted_index = np.argmax(predicted_onehot, axis = 1) #, len(vocab)-1)\n",
    "    predicted_char = [vocab[idx] for idx in predicted_index]\n",
    "    # Reverts deque length to seq_length:\n",
    "    pred_list += predicted_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual training\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:10000]))\n",
    "# 0.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3244"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 4 skip, not a huge loss\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6756"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 4 skip, not a huge loss\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:20000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9449"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 4 skip, not a huge loss\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:30000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try full LSTM\n",
    "\n",
    "This allows us to understand LSTM full capability of predicting DNA sequences, given full information. Note that LSTM would certainly performs better if we have extrenal DNA data to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4638690\n"
     ]
    }
   ],
   "source": [
    "print(len(ecoli))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4638626 samples\n",
      "4638626/4638626 [==============================] - 1560s 336us/sample - loss: 1.3450 - categorical_accuracy: 0.3385\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "vocab = ['a','t','c','g']\n",
    "legend = dict([(v, k) for k, v in enumerate(vocab)])\n",
    "ecoli_temp = copy.deepcopy(ecoli)\n",
    "pred_list = ecoli_temp[:64]\n",
    "\n",
    "x = np.zeros((len(ecoli)-64, 64, 1))\n",
    "y = np.zeros((len(ecoli)-64, 4))\n",
    "\n",
    "x_pred = np.zeros((len(ecoli)-64, 64, 1))\n",
    "j = 64\n",
    "for k in range(len(ecoli)-64):\n",
    "    train_seq = [legend[i] for i in ecoli_temp[j-64+k:j+k]] \n",
    "    train_target = legend[ecoli_temp[j+k]]\n",
    "    pred_seq = [legend[i] for i in ecoli_temp[j-64+k:j+k]] \n",
    "    x_pred[k,:] = np.array(pred_seq).reshape((64,1))\n",
    "    x[k,:] = np.array(train_seq).reshape((64,1))\n",
    "    y[k,:] = to_categorical( train_target, num_classes=vocab_size )\n",
    "    \n",
    "model.fit(x=x, y=y, batch_size=32, epochs=1)\n",
    "predicted_onehot = model.predict(x_pred)\n",
    "predicted_index = np.argmax(predicted_onehot, axis = 1) #, len(vocab)-1)\n",
    "predicted_char = [vocab[idx] for idx in predicted_index]\n",
    "pred_list += predicted_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3526116209533295"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(pred_list) == np.array(ecoli_temp))/len(ecoli_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2542144441641929"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base\n",
    "1179222/len(ecoli_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see an improvement of LSTM over 3-Gram/ random (about 32-35% instead of 25%, higher if using external information). However, this does not leverage any actual prior knowledge about DNA structure. Also, not practical in real life due to high computation trade-off despite better compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's actually leverage DNA Characteristics: Palindromic Nature\n",
    "\n",
    "DNA tends to be palindromic in nature, but in a complementary way. For instance, CAATTG complementary is GTTAAC which is equal if we read the complementary backwards. As for normal palindrome, those also exists, such as, CAAC.  \n",
    "\n",
    "We will cound the number of palindrome sequence and average range below for both real and fake DNA\n",
    "\n",
    "### Interestingly, we randomly sample a period and there is no distinction between EColi and Fake EColi in terms of Palindrome number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49729"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countSubstrings(s: str) -> int:\n",
    "        n = len(s)\n",
    "        dp = [[0] * n for _ in range(n)]\n",
    "        \n",
    "        \n",
    "        res = 0\n",
    "        for i in range(n-1, -1, -1):\n",
    "            for j in range(i, n):\n",
    "                dp[i][j] = s[i] == s[j] and ((j-i+1) < 3 or dp[i+1][j-1])\n",
    "                res += dp[i][j]\n",
    "        return res\n",
    "countSubstrings(ecoli[100000:130000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50289"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countSubstrings(fecoli[100000:130000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count DNA palindrome: this means A wouldn't count, AT, however, would count. and it's still pretty much similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10251"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def countSubstrings_DNA(s: str) -> int:\n",
    "        n = len(s)\n",
    "        dp = [[0] * n for _ in range(n)]\n",
    "        DNAdict = {'a':'t','t':'a','c':'g','g':'c'}\n",
    "        \n",
    "        res = 0\n",
    "        for i in range(n-1, -1, -1):\n",
    "            for j in range(i, n):\n",
    "                dp[i][j] = s[i] == DNAdict[s[j]] and ((j-i+1) < 3 or dp[i+1][j-1])\n",
    "                res += dp[i][j]\n",
    "        return res\n",
    "countSubstrings_DNA(ecoli[100000:130000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9930"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countSubstrings_DNA(fecoli[100000:130000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's actually leverage DNA Characteristics: Repeating Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat length 2\n",
      "max streak 6\n",
      "EColi count 201463\n",
      "EColi avg. repeats 2.068022416026764\n",
      "max streak 6\n",
      "Fake EColi count 217875\n",
      "Fake EColi avg. repeats 2.065936890418818\n",
      "Repeat length 3\n",
      "max streak 5\n",
      "EColi count 77573\n",
      "EColi avg. repeats 2.0324339654261148\n",
      "max streak 4\n",
      "Fake EColi count 54358\n",
      "Fake EColi avg. repeats 2.0170904006769934\n",
      "Repeat length 4\n",
      "max streak 4\n",
      "EColi count 13781\n",
      "EColi avg. repeats 2.003918438429722\n",
      "max streak 3\n",
      "Fake EColi count 13661\n",
      "Fake EColi avg. repeats 2.00461166825269\n",
      "Repeat length 5\n",
      "max streak 2\n",
      "EColi count 3584\n",
      "EColi avg. repeats 2.0\n",
      "max streak 3\n",
      "Fake EColi count 3341\n",
      "Fake EColi avg. repeats 2.0014965579167914\n",
      "Repeat length 6\n",
      "max streak 3\n",
      "EColi count 2034\n",
      "EColi avg. repeats 2.0014749262536875\n",
      "max streak 2\n",
      "Fake EColi count 834\n",
      "Fake EColi avg. repeats 2.0\n",
      "Repeat length 7\n",
      "max streak 2\n",
      "EColi count 238\n",
      "EColi avg. repeats 2.0\n",
      "max streak 2\n",
      "Fake EColi count 222\n",
      "Fake EColi avg. repeats 2.0\n",
      "Repeat length 8\n",
      "max streak 6\n",
      "EColi count 68\n",
      "EColi avg. repeats 2.1323529411764706\n",
      "max streak 2\n",
      "Fake EColi count 49\n",
      "Fake EColi avg. repeats 2.0\n",
      "Repeat length 9\n",
      "max streak 2\n",
      "EColi count 44\n",
      "EColi avg. repeats 2.0\n",
      "max streak 2\n",
      "Fake EColi count 17\n",
      "Fake EColi avg. repeats 2.0\n",
      "Repeat length 10\n",
      "max streak 2\n",
      "EColi count 4\n",
      "EColi avg. repeats 2.0\n",
      "max streak 2\n",
      "Fake EColi count 3\n",
      "Fake EColi avg. repeats 2.0\n",
      "Repeat length 11\n",
      "max streak 2\n",
      "EColi count 2\n",
      "EColi avg. repeats 2.0\n",
      "max streak 2\n",
      "Fake EColi count 1\n",
      "Fake EColi avg. repeats 2.0\n",
      "Repeat length 12\n",
      "max streak 2\n",
      "EColi count 1\n",
      "EColi avg. repeats 2.0\n",
      "max streak 0\n",
      "Repeat length 13\n",
      "max streak 0\n",
      "max streak 2\n",
      "Fake EColi count 1\n",
      "Fake EColi avg. repeats 2.0\n",
      "Repeat length 14\n",
      "max streak 2\n",
      "EColi count 2\n",
      "EColi avg. repeats 2.0\n",
      "max streak 0\n",
      "Repeat length 15\n",
      "max streak 2\n",
      "EColi count 2\n",
      "EColi avg. repeats 2.0\n",
      "max streak 0\n",
      "Repeat length 16\n",
      "max streak 3\n",
      "EColi count 2\n",
      "EColi avg. repeats 3.0\n",
      "max streak 0\n",
      "Repeat length 17\n",
      "max streak 2\n",
      "EColi count 1\n",
      "EColi avg. repeats 2.0\n",
      "max streak 0\n",
      "Repeat length 18\n",
      "max streak 0\n",
      "max streak 0\n",
      "Repeat length 19\n",
      "max streak 2\n",
      "EColi count 1\n",
      "EColi avg. repeats 2.0\n",
      "max streak 0\n"
     ]
    }
   ],
   "source": [
    "def Repeatsearch(s: str, k:int) -> int:\n",
    "        n = len(s)\n",
    "        count = 0\n",
    "        length = 0\n",
    "        streak = 0\n",
    "        max_streak = 0\n",
    "        i = 0\n",
    "        while i < n-k-1:\n",
    "            if s[i:i+k] == s[i+k:i+2*k]:\n",
    "                streak += 1\n",
    "                i+=k\n",
    "            elif streak > 0:\n",
    "                count += 1\n",
    "                length += streak+1\n",
    "                max_streak = max(max_streak,streak+1)\n",
    "                streak = 0\n",
    "                i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "            \n",
    "        print('max streak ' + str(max_streak))      \n",
    "        return count, length\n",
    "for k in range(2,20):\n",
    "    print('Repeat length '+str(k))\n",
    "    count, length = Repeatsearch(ecoli,k)\n",
    "    if count != 0:\n",
    "        print('EColi count ' + str(count))\n",
    "        print('EColi avg. repeats ' + str(length/count))\n",
    "    count, length = Repeatsearch(fecoli,k)\n",
    "    if count != 0:\n",
    "        print('Fake EColi count ' + str(count))\n",
    "        print('Fake EColi avg. repeats ' + str(length/count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's count consecutive repetition\n",
    "\n",
    "Note that 4 consecutive, like AAAA can be written as A4 so it saves the same amount as ATCATC to ATC3 so it has to beat 77573."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3564238079837558\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "import numpy as np\n",
    "consec_count = [len(list(g)) for k,g in groupby(list(ecoli))]\n",
    "print(np.mean(consec_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3340118392475888\n"
     ]
    }
   ],
   "source": [
    "consec_count_fake = [len(list(g)) for k,g in groupby(list(fecoli))]\n",
    "print(np.mean(consec_count_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6800427160232658"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(consec_count)/np.mean(consec_count_fake)*100 - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679312\n",
      "163460\n",
      "42951\n"
     ]
    }
   ],
   "source": [
    "### Does this warrant becoming its own character? prob not, it's less than length 2 (200k)\n",
    "print(sum(np.array(consec_count) == 2))\n",
    "print(sum(np.array(consec_count) == 3))\n",
    "print(sum(np.array(consec_count) == 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653006\n",
      "163273\n",
      "40983\n"
     ]
    }
   ],
   "source": [
    "print(sum(np.array(consec_count_fake) == 2))\n",
    "print(sum(np.array(consec_count_fake) == 3))\n",
    "print(sum(np.array(consec_count_fake) == 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
