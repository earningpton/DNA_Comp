{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do Exploratory Data Analysis for E.Coli by comparing it to fake ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = []\n",
    "with open('data\\ecoli\\Ecoli.txt') as f:\n",
    "    for line in f:\n",
    "        #inner_list = [elt.strip() for elt in line.split()]\n",
    "        inner_list = list(line)\n",
    "        list_of_lists.append(inner_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4638690\n"
     ]
    }
   ],
   "source": [
    "# There is only 1 line\n",
    "print(len(list_of_lists[0])) # About 4 MB\n",
    "ecoli = list_of_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\ecoli\\Fake_Ecoli.txt') as f:\n",
    "    for line in f:\n",
    "        #inner_list = [elt.strip() for elt in line.split()]\n",
    "        fecoli = list(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'c': 1179222, 'g': 1176575, 'a': 1142069, 't': 1140824})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(ecoli)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'c': 1178622, 'g': 1178186, 'a': 1141315, 't': 1140567})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(fecoli)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is preference in nature, as exhbited by the order of 2 in Ecoli vs Fake Ecoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gc': 383734, 'cg': 346554, 'tt': 339460, 'aa': 337820, 'ca': 325090, 'tg': 322170, 'at': 309781, 'cc': 271591, 'gg': 270025, 'tc': 267255, 'ga': 267219, 'ac': 256642, 'gt': 255597, 'ag': 237826, 'ct': 235986, 'ta': 211939})\n"
     ]
    }
   ],
   "source": [
    "ecoli_2 = [ecoli[i]+ecoli[i+1] for i in range(len(ecoli)-1)]\n",
    "counter=collections.Counter(ecoli_2)\n",
    "print(counter)\n",
    "# there are 4*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'cc': 299846, 'gg': 299710, 'cg': 298861, 'gc': 298814, 'ca': 290554, 'ag': 290467, 'tc': 290147, 'gt': 289896, 'ac': 289815, 'ga': 289766, 'ct': 289361, 'tg': 289148, 'tt': 281082, 'aa': 280804, 'at': 280228, 'ta': 280190})\n"
     ]
    }
   ],
   "source": [
    "fecoli_2 = [fecoli[i]+fecoli[i+1] for i in range(len(fecoli)-1)]\n",
    "counter=collections.Counter(fecoli_2)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is even stronger preference in nature, as exhbited by the order of 4 in Ecoli vs Fake Ecoli\n",
    "\n",
    "The starkest contrast is the range with 'cagc' and 'gctg' occuring 37000 times as opposed to ctag which only occurs 900 times. The fake ecoli shows a more 'statistical' distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ecoli_4 = [ecoli[i]+ecoli[i+1]+ecoli[i+2]+ecoli[i+3]   for i in range(len(ecoli)-3)]\n",
    "counter=collections.Counter(ecoli_4)\n",
    "#print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fecoli_4 = [fecoli[i]+fecoli[i+1]+fecoli[i+2]+fecoli[i+3]   for i in range(len(fecoli)-3)]\n",
    "counter=collections.Counter(fecoli_4)\n",
    "#print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try bag of word model, to see if it works better for the real file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = {}\n",
    "words = 4\n",
    "\n",
    "words_tokens = ecoli\n",
    "for i in range(len(words_tokens)-words):\n",
    "    seq = ' '.join(words_tokens[i:i+words])\n",
    "    #print(seq)\n",
    "    if  seq not in ngrams.keys():\n",
    "        ngrams[seq] = []\n",
    "    ngrams[seq].append(words_tokens[i+words])\n",
    "curr_sequence = ' '.join(words_tokens[0:words])\n",
    "output = curr_sequence\n",
    "for i in range(3000):\n",
    "    if curr_sequence not in ngrams.keys():\n",
    "        break\n",
    "    possible_words = ngrams[curr_sequence]\n",
    "    next_word = possible_words[random.randrange(len(possible_words))]\n",
    "    output += ' ' + next_word\n",
    "    seq_words = output.split(' ')\n",
    "    curr_sequence = ' '.join(seq_words[len(seq_words)-words:len(seq_words)])\n",
    "\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3004"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output)\n",
    "temp = ''.join(output.split(' '))\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'cagc': 3014, 'aaaa': 2932, 'gctg': 2844, 'gcgc': 2706, 'ccag': 2674, 'tttt': 2662, 'ggcg': 2640, 'ctgg': 2631, 'cgcc': 2603, 'gcca': 2465, 'tggc': 2411, 'gcag': 2354, 'ctgc': 2253, 'cggc': 2218, 'cgcg': 2216, 'gcgg': 2190, 'ccgc': 2188, 'gaaa': 2180, 'tgcc': 2179, 'gccg': 2177, 'tgat': 2176, 'atca': 2160, 'ttgc': 2155, 'ggca': 2118, 'aaat': 2085, 'gcaa': 2083, 'acgc': 2082, 'gatg': 2075, 'agcg': 2064, 'cgct': 2050, 'catc': 2034, 'tttc': 2030, 'aaac': 2025, 'gcgt': 2017, 'tgaa': 2015, 'ttca': 2014, 'cgca': 2011, 'gcga': 1976, 'cctg': 1974, 'tgcg': 1969, 'acca': 1944, 'gttt': 1920, 'accg': 1917, 'aacg': 1911, 'tcgc': 1904, 'caaa': 1901, 'attt': 1901, 'tggt': 1897, 'ctga': 1882, 'cgat': 1876, 'tttg': 1875, 'atcg': 1869, 'cagg': 1865, 'cgtt': 1859, 'cacc': 1858, 'cggt': 1857, 'agca': 1855, 'tcag': 1849, 'ggtg': 1827, 'ccgg': 1805, 'cttt': 1773, 'caga': 1770, 'caac': 1755, 'taaa': 1754, 'tgct': 1740, 'ataa': 1729, 'aaag': 1725, 'cttc': 1711, 'gcat': 1707, 'gttg': 1694, 'aaca': 1694, 'aatc': 1689, 'ttat': 1689, 'ttta': 1688, 'tgtt': 1677, 'catt': 1669, 'atga': 1662, 'aacc': 1659, 'gaag': 1658, 'aata': 1651, 'aatg': 1646, 'caat': 1642, 'tatt': 1635, 'actg': 1634, 'ggaa': 1634, 'attg': 1631, 'tcat': 1623, 'tctg': 1613, 'atgg': 1609, 'gata': 1599, 'gatt': 1598, 'ttaa': 1596, 'atgc': 1583, 'tcaa': 1573, 'cagt': 1573, 'tatc': 1570, 'ttcc': 1560, 'tcac': 1559, 'ccat': 1550, 'ggtt': 1550, 'aagc': 1549, 'gctt': 1532, 'atat': 1531, 'tgca': 1518, 'agaa': 1502, 'gatc': 1501, 'gtga': 1499, 'gtca': 1479, 'atta': 1475, 'ccgt': 1474, 'aatt': 1473, 'cgaa': 1473, 'atcc': 1473, 'ccac': 1470, 'ttga': 1467, 'ttcg': 1467, 'cgtc': 1465, 'agcc': 1461, 'ttct': 1450, 'gaac': 1424, 'gtgg': 1418, 'gtgc': 1415, 'acgg': 1407, 'tgac': 1389, 'ggat': 1388, 'gttc': 1382, 'ttac': 1379, 'taat': 1370, 'attc': 1368, 'gacg': 1363, 'gaat': 1362, 'tctt': 1360, 'gcac': 1358, 'taac': 1357, 'tccg': 1350, 'acag': 1345, 'aaga': 1343, 'ggct': 1342, 'cgac': 1341, 'tacc': 1341, 'gtaa': 1341, 'agat': 1333, 'tgga': 1333, 'gtcg': 1329, 'gtta': 1323, 'acaa': 1318, 'ggta': 1315, 'tcca': 1313, 'ttgt': 1305, 'ctgt': 1299, 'cgga': 1299, 'aact': 1297, 'atct': 1292, 'gcct': 1291, 'cgtg': 1279, 'cacg': 1273, 'cggg': 1267, 'cccg': 1261, 'tcgg': 1239, 'ccga': 1238, 'agtt': 1233, 'tcga': 1232, 'gccc': 1232, 'aggc': 1218, 'catg': 1182, 'gggc': 1175, 'tacg': 1123, 'acgt': 1110, 'tcgt': 1105, 'cgta': 1103, 'atgt': 1098, 'acat': 1092, 'cact': 1090, 'ccaa': 1090, 'cata': 1087, 'acct': 1079, 'atac': 1078, 'cctt': 1073, 'acga': 1071, 'gtat': 1070, 'gaca': 1065, 'ccca': 1062, 'gagc': 1055, 'tatg': 1049, 'agtg': 1049, 'aagg': 1045, 'agct': 1043, 'ggtc': 1042, 'tggg': 1038, 'gacc': 1036, 'ttgg': 1021, 'aggt': 1018, 'actt': 1011, 'tgtg': 1007, 'caca': 994, 'tgtc': 990, 'gctc': 984, 'aagt': 984, 'gggt': 962, 'gaga': 960, 'tctc': 958, 'accc': 954, 'ctca': 951, 'gtac': 942, 'tgag': 930, 'ggcc': 922, 'ggga': 903, 'agag': 901, 'tcct': 893, 'agga': 877, 'tgta': 858, 'tccc': 853, 'agta': 847, 'agac': 834, 'taca': 830, 'gtgt': 830, 'acac': 828, 'cgag': 827, 'tact': 825, 'ctct': 820, 'ctcg': 815, 'gcta': 815, 'tagc': 804, 'gagt': 793, 'gtct': 786, 'actc': 779, 'taag': 772, 'gtag': 770, 'caag': 766, 'ggag': 763, 'cttg': 748, 'ctcc': 746, 'ctta': 744, 'cccc': 744, 'aggg': 735, 'agtc': 727, 'gact': 727, 'tata': 721, 'ctac': 720, 'atag': 720, 'ccct': 716, 'ctat': 685, 'gtcc': 630, 'gggg': 628, 'ggac': 627, 'gagg': 613, 'cctc': 611, 'ctaa': 587, 'ttag': 566, 'acta': 515, 'tagt': 506, 'taga': 497, 'tcta': 417, 'tagg': 325, 'ccta': 321, 'ctag': 76})\n"
     ]
    }
   ],
   "source": [
    "fecoli_4 = [temp[i]+temp[i+1]+temp[i+2]+temp[i+3]   for i in range(len(temp)-3)]\n",
    "counter=collections.Counter(fecoli_4)\n",
    "#print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "seq_length = 64  #Length of the sequence to be inserted into the LSTM\n",
    "vocab_size = 4  #Size of the final dense layer of the model\n",
    "lstm_cells = 16  #Size of the LSTM layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_cells, input_shape=(seq_length, 1)))\n",
    "model.add(Dense(vocab_size))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = ['a','t','c','g']\n",
    "legend = dict([(v, k) for k, v in enumerate(vocab)])\n",
    "from keras.utils import to_categorical\n",
    "to_categorical(legend['a'],num_classes = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "vocab = ['a','t','c','g']\n",
    "legend = dict([(v, k) for k, v in enumerate(vocab)])\n",
    "ecoli_temp = copy.deepcopy(ecoli)\n",
    "pred_list = ecoli_temp[:64]\n",
    "for j in range(64,3000,100):\n",
    "\n",
    "    # At this point, please note that the length of the deque is seq_length + 1.\n",
    "    \n",
    "    # Dictionary to convert numbers to classes:\n",
    "    x = np.zeros((100, 64, 1))\n",
    "    y = np.zeros((100, 4))\n",
    "    \n",
    "    x_pred = np.zeros((100, seq_length, 1))\n",
    "    \n",
    "    for k in range(100):\n",
    "        # Converts the deque into a list:\n",
    "        # Each iteration is comprised of 1 training and 1 prediction. These are the training sequence and target:\n",
    "        train_seq = [legend[i] for i in ecoli_temp[j-64+k:j+k]] \n",
    "        train_target = legend[ecoli_temp[j+k]]\n",
    "        # And the prediction sequence just shifts the window by 1:\n",
    "        pred_seq = [legend[i] for i in ecoli_temp[j-63+99+k:j+1+99+k]]\n",
    "        x_pred[k,:] = np.array(pred_seq).reshape((64,1))\n",
    "        # Batches data into a batch of size 1:\n",
    "        \n",
    "        \n",
    "        x[k,:] = np.array(train_seq).reshape((64,1))\n",
    "        y[k,:] = to_categorical( train_target, num_classes=vocab_size )\n",
    "        # Online training:\n",
    "        model.fit(x=x, y=y, batch_size=32, epochs=1, verbose=0)\n",
    "\n",
    "    # Now that one training step is done, make a prediction:\n",
    "    \n",
    "    predicted_onehot = model.predict(x_pred)\n",
    "    # Avoids \"index out of range\" erros when the LSTM vocab is still being built:\n",
    "    predicted_index = np.argmax(predicted_onehot, axis = 1) #, len(vocab)-1)\n",
    "    predicted_char = [vocab[idx] for idx in predicted_index]\n",
    "    # Reverts deque length to seq_length:\n",
    "    pred_list += predicted_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3064"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32114882506527415"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With batch training\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:3064]))\n",
    "984/3064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Individual training\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3244"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 4 skip, not a huge loss\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6756"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 4 skip, not a huge loss\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:20000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9449"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 4 skip, not a huge loss\n",
    "np.sum(np.array(pred_list) == np.array(ecoli_temp[:30000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With 3 gram\n",
    "temp2 = list(temp)\n",
    "np.sum(np.array(temp2[:1000]) == np.array(ecoli_temp[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see an improvement of LSTM over 3-Gram. However, this does not leverage any actual knowledge about DNA structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
