{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier is an ensemble model that has proven to be fast and robust\n",
    "\n",
    "This puts its speed closer to Ipaq8 rather than LSTM sluggishness\n",
    "\n",
    "This is a proof of concept. No future data is ever used so we can turn it into exe ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01 0.99]]\n",
      "(1000, 4)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(criterion='entropy',max_depth=None, random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.predict_proba([[0, 0, 0, 0]]))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4638690\n"
     ]
    }
   ],
   "source": [
    "list_of_lists = []\n",
    "with open('data\\ecoli\\Ecoli.txt') as f:\n",
    "    for line in f:\n",
    "        #inner_list = [elt.strip() for elt in line.split()]\n",
    "        inner_list = list(line)\n",
    "        list_of_lists.append(inner_list)\n",
    "print(len(list_of_lists[0])) # About 4 MB\n",
    "ecoli = list_of_lists[0]\n",
    "\n",
    "import arithc as arith\n",
    "import fqt, ppm\n",
    "import contextlib, sys\n",
    "import filecmp\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from plist import ProbabilityList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Warm start:\n",
    "\n",
    "We build additional trees every 100,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ecoli\n",
    "char_list = [97, 103, 99, 116] # we can read this as we go\n",
    "print(char_list)\n",
    "update_period = len(s)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, warm_start = True, random_state=0)\n",
    "\n",
    "legend = dict([(v, k) for k, v in enumerate(char_list)]) # map character to 0,1,2,3,4, etc.\n",
    "\n",
    "temp_dict = {'a':97,'g': 103,'c': 99,'t': 116}\n",
    "s = [temp_dict[i] for i in s]\n",
    "#Train model\n",
    "x = np.zeros((update_period-128, 128)) # 128 characters context\n",
    "y = np.zeros((update_period-128))\n",
    "\n",
    "print(len(s))\n",
    "idx3 = 0\n",
    "for idx2 in range(128,len(s)):\n",
    "    train_seq = [legend[i] for i in s[idx2-128:idx2]] \n",
    "    train_target = legend[s[idx2]]\n",
    "    x[idx3,:] = np.array(train_seq)\n",
    "    y[idx3] = train_target\n",
    "    idx3 += 1\n",
    "predicted_onehot = []\n",
    "for i in range(len(ecoli)//200000 - 1):\n",
    "    print(i)\n",
    "    rf.fit(x[200000*i:200000*(i+1)], y[200000*i:200000*(i+1)])\n",
    "    rf.n_estimators += 10\n",
    "\n",
    "    predicted_onehot += list(rf.predict_proba(x[200000*(i+1):200000*(i+2)]))\n",
    "predicted_onehot += list(rf.predict_proba(x[200000*(len(ecoli)//200000):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('temp', predicted_onehot)\n",
    "predicted_onehot = np.load('temp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "char_list = [97, 103, 99, 116]\n",
    "def RF_Warmcompress(inp, bitout):\n",
    "    initfreqs = fqt.FlatFrequencyTable(257)\n",
    "    model = fqt.SimpleFrequencyTable(initfreqs) # For the first 200,000\n",
    "    enc = arith.ArithmeticCoder(32)\n",
    "    enc.start_encode(bitout) # New line!\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        symbol = inp.read(1)\n",
    "        if len(symbol) == 0:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        print(idx)\n",
    "        ## Progress Evaluation ## only internal\n",
    "        if idx % (len(ecoli)//10) == 0:\n",
    "            print(str(10*idx//(len(ecoli)//10)) + ' percent done')\n",
    "            clear_output(wait = True)\n",
    "        if idx == 200129:\n",
    "            initfreqs = fqt.FlatFrequencyTable(257)\n",
    "            model = fqt.SimpleFrequencyTable(initfreqs) # reset the model\n",
    "        if idx >= 200129:\n",
    "            for val, prob in enumerate(predicted_onehot[idx-200129]):\n",
    "                model.set(char_list[val], int(prob*100000)+1)\n",
    "            \n",
    "        t = model.get_total() ## New lines!\n",
    "        l = model.get_low(symbol[0])\n",
    "        h = model.get_high(symbol[0])\n",
    "        enc.storeRegion(l,h,t) \n",
    "        \n",
    "        if idx < 200129: # back up before LSTM model\n",
    "            model.increment(symbol[0])\n",
    "    t = model.get_total() ## New lines!\n",
    "    l = model.get_low(256)\n",
    "    h = model.get_high(256)\n",
    "    enc.storeRegion(l,h,t)\n",
    "    enc.finish_encode(bitout)  # New line!\n",
    "inputfile, outputfile = 'data\\ecoli\\Ecoli.txt', 'data\\ecoli\\Ecoli_RF_warm.txt'\n",
    "\n",
    "#Perform file compression\n",
    "with open(inputfile, \"rb\") as inp, \\\n",
    "        contextlib.closing(arith.BitOutputStream(open(outputfile, \"wb\"))) as bitout:\n",
    "    RF_Warmcompress(inp, bitout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ecoli\n",
    "char_list = [97, 103, 99, 116] # we can read this as we go\n",
    "print(char_list)\n",
    "update_period = len(s)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, warm_start = True, random_state=0)\n",
    "\n",
    "legend = dict([(v, k) for k, v in enumerate(char_list)]) # map character to 0,1,2,3,4, etc.\n",
    "\n",
    "temp_dict = {'a':97,'g': 103,'c': 99,'t': 116}\n",
    "s = [temp_dict[i] for i in s]\n",
    "#Train model\n",
    "x = np.zeros((update_period-128, 128)) # 128 characters context\n",
    "y = np.zeros((update_period-128))\n",
    "\n",
    "print(len(s))\n",
    "idx3 = 0\n",
    "for idx2 in range(128,len(s)):\n",
    "    train_seq = [legend[i] for i in s[idx2-128:idx2]] \n",
    "    train_target = legend[s[idx2]]\n",
    "    x[idx3,:] = np.array(train_seq)\n",
    "    y[idx3] = train_target\n",
    "    idx3 += 1\n",
    "predicted_onehot = []\n",
    "for i in range(len(ecoli)//200000 - 1):\n",
    "    rf.fit(x[200000*i:200000*(i+1)], y[200000*i:200000*(i+1)])\n",
    "    rf.n_estimators += 5\n",
    "\n",
    "    predicted_onehot += list(rf.predict_proba(x[200000*(i+1):200000*(i+2)]))\n",
    "predicted_onehot += list(rf.predict_proba(x[200000*(len(ecoli)//200000):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('temp2', predicted_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_Warmcompress(inp, bitout):\n",
    "    initfreqs = fqt.FlatFrequencyTable(257)\n",
    "    model = fqt.SimpleFrequencyTable(initfreqs) # For the first 200,000\n",
    "    enc = arith.ArithmeticCoder(32)\n",
    "    enc.start_encode(bitout) # New line!\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        symbol = inp.read(1)\n",
    "        if len(symbol) == 0:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        ## Progress Evaluation ## only internal\n",
    "        if idx % (len(ecoli)//10) == 0:\n",
    "            print(str(10*idx//(len(ecoli)//10)) + ' percent done')\n",
    "            clear_output(wait = True)\n",
    "        if idx == 200129:\n",
    "            initfreqs = fqt.FlatFrequencyTable(257)\n",
    "            model = fqt.SimpleFrequencyTable(initfreqs) # reset the model\n",
    "        if idx >= 200129:\n",
    "            for val, prob in enumerate(predicted_onehot[idx-200129]):\n",
    "                model.set(char_list[val], int(prob*100000)+1)\n",
    "            \n",
    "        t = model.get_total() ## New lines!\n",
    "        l = model.get_low(symbol[0])\n",
    "        h = model.get_high(symbol[0])\n",
    "        enc.storeRegion(l,h,t) \n",
    "        \n",
    "        if idx < 200129: # back up before LSTM model\n",
    "            model.increment(symbol[0])\n",
    "    t = model.get_total() ## New lines!\n",
    "    l = model.get_low(256)\n",
    "    h = model.get_high(256)\n",
    "    enc.storeRegion(l,h,t)\n",
    "    enc.finish_encode(bitout)  # New line!\n",
    "inputfile, outputfile = 'data\\ecoli\\Ecoli.txt', 'data\\ecoli\\Ecoli_RF_warm2.txt'\n",
    "\n",
    "#Perform file compression\n",
    "with open(inputfile, \"rb\") as inp, \\\n",
    "        contextlib.closing(arith.BitOutputStream(open(outputfile, \"wb\"))) as bitout:\n",
    "    RF_Warmcompress(inp, bitout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Decision Tree instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01 0.99]]\n",
      "(1000, 4)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(criterion='entropy',max_depth=None, random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.predict_proba([[0, 0, 0, 0]]))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4638690\n"
     ]
    }
   ],
   "source": [
    "list_of_lists = []\n",
    "with open('data\\ecoli\\Ecoli.txt') as f:\n",
    "    for line in f:\n",
    "        #inner_list = [elt.strip() for elt in line.split()]\n",
    "        inner_list = list(line)\n",
    "        list_of_lists.append(inner_list)\n",
    "print(len(list_of_lists[0])) # About 4 MB\n",
    "ecoli = list_of_lists[0]\n",
    "\n",
    "import arithc as arith\n",
    "import fqt, ppm\n",
    "import contextlib, sys\n",
    "import filecmp\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 103, 99, 116]\n",
      "4638690\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "s = ecoli\n",
    "char_list = [97, 103, 99, 116] # we can read this as we go\n",
    "print(char_list)\n",
    "update_period = len(s)\n",
    "\n",
    "clf  = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "legend = dict([(v, k) for k, v in enumerate(char_list)]) # map character to 0,1,2,3,4, etc.\n",
    "\n",
    "temp_dict = {'a':97,'g': 103,'c': 99,'t': 116}\n",
    "s = [temp_dict[i] for i in s]\n",
    "#Train model\n",
    "x = np.zeros((update_period-128, 128)) # 128 characters context\n",
    "y = np.zeros((update_period-128))\n",
    "\n",
    "print(len(s))\n",
    "idx3 = 0\n",
    "for idx2 in range(128,len(s)):\n",
    "    train_seq = [legend[i] for i in s[idx2-128:idx2]] \n",
    "    train_target = legend[s[idx2]]\n",
    "    x[idx3,:] = np.array(train_seq)\n",
    "    y[idx3] = train_target\n",
    "    idx3 += 1\n",
    "predicted_onehot = []\n",
    "for i in range(len(ecoli)//200000 - 1):\n",
    "    print(i)\n",
    "    clf.fit(x[200000*i:200000*(i+1)], y[200000*i:200000*(i+1)])\n",
    "\n",
    "    predicted_onehot += list(clf.predict_proba(x[200000*(i+1):200000*(i+2)]))\n",
    "predicted_onehot += list(clf.predict_proba(x[200000*(len(ecoli)//200000):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_onehot[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 percent done\n"
     ]
    }
   ],
   "source": [
    "def DCTcompress(inp, bitout):\n",
    "    initfreqs = fqt.FlatFrequencyTable(257)\n",
    "    model = fqt.SimpleFrequencyTable(initfreqs) # For the first 200,000\n",
    "    enc = arith.ArithmeticCoder(32)\n",
    "    enc.start_encode(bitout) # New line!\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        symbol = inp.read(1)\n",
    "        if len(symbol) == 0:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        ## Progress Evaluation ## only internal\n",
    "        if idx % (len(ecoli)//10) == 0:\n",
    "            print(str(10*idx//(len(ecoli)//10)) + ' percent done')\n",
    "            clear_output(wait = True)\n",
    "        if idx == 200129:\n",
    "            initfreqs = fqt.FlatFrequencyTable(257)\n",
    "            model = fqt.SimpleFrequencyTable(initfreqs) # reset the model\n",
    "        if idx >= 200129:\n",
    "            for val, prob in enumerate(predicted_onehot[idx-200129]):\n",
    "                model.set(char_list[val], int(prob*12000)+22000)\n",
    "            \n",
    "        t = model.get_total() ## New lines!\n",
    "        l = model.get_low(symbol[0])\n",
    "        h = model.get_high(symbol[0])\n",
    "        enc.storeRegion(l,h,t) \n",
    "        \n",
    "        if idx < 200129: # back up before LSTM model\n",
    "            model.increment(symbol[0])\n",
    "    t = model.get_total() ## New lines!\n",
    "    l = model.get_low(256)\n",
    "    h = model.get_high(256)\n",
    "    enc.storeRegion(l,h,t)\n",
    "    enc.finish_encode(bitout)  # New line!\n",
    "inputfile, outputfile = 'data\\ecoli\\Ecoli.txt', 'data\\ecoli\\Ecoli_DCT.txt'\n",
    "\n",
    "#Perform file compression\n",
    "with open(inputfile, \"rb\") as inp, \\\n",
    "        contextlib.closing(arith.BitOutputStream(open(outputfile, \"wb\"))) as bitout:\n",
    "    DCTcompress(inp, bitout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 103, 99, 116]\n",
      "4638690\n",
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "s = ecoli\n",
    "char_list = [97, 103, 99, 116] # we can read this as we go\n",
    "print(char_list)\n",
    "update_period = len(s)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=20, warm_start = True, random_state=0)\n",
    "\n",
    "legend = dict([(v, k) for k, v in enumerate(char_list)]) # map character to 0,1,2,3,4, etc.\n",
    "\n",
    "temp_dict = {'a':97,'g': 103,'c': 99,'t': 116}\n",
    "s = [temp_dict[i] for i in s]\n",
    "#Train model\n",
    "x = np.zeros((update_period-64, 64)) # 64 characters context\n",
    "y = np.zeros((update_period-64))\n",
    "\n",
    "print(len(s))\n",
    "idx3 = 0\n",
    "for idx2 in range(64,len(s)):\n",
    "    train_seq = [legend[i] for i in s[idx2-64:idx2]] \n",
    "    train_target = legend[s[idx2]]\n",
    "    x[idx3,:] = np.array(train_seq)\n",
    "    y[idx3] = train_target\n",
    "    idx3 += 1\n",
    "predicted_onehot = []\n",
    "for i in range(len(ecoli)//100000 - 1):\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "    rf.fit(x[100000*i:100000*(i+1)], y[100000*i:100000*(i+1)])\n",
    "    rf.n_estimators += 10\n",
    "\n",
    "    predicted_onehot += list(rf.predict_proba(x[100000*(i+1):100000*(i+2)]))\n",
    "predicted_onehot += list(rf.predict_proba(x[100000*(len(ecoli)//100000):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 percent done\n"
     ]
    }
   ],
   "source": [
    "char_list = [97, 103, 99, 116]\n",
    "def RF_Warmcompress(inp, bitout):\n",
    "    initprobs= [1/257 for i in range(257)]\n",
    "    initprobs[256] = 1-sum(initprobs[:256])\n",
    "    model = ProbabilityList(initprobs) # For the first 200,000\n",
    "    enc = arith.ArithmeticCoder(32)\n",
    "    enc.start_encode(bitout) # New line!\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        symbol = inp.read(1)\n",
    "        if len(symbol) == 0:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "        ## Progress Evaluation ## only internal\n",
    "        if idx % (len(ecoli)//10) == 0:\n",
    "            print(str(10*idx//(len(ecoli)//10)) + ' percent done')\n",
    "            clear_output(wait = True)\n",
    "        if idx == 100065:\n",
    "            model = ProbabilityList(initprobs) # reset the model\n",
    "        if idx >= 100065:\n",
    "            for val, prob in enumerate(predicted_onehot[idx-100065]):\n",
    "                model.set_prob(char_list[val], prob+1/257)\n",
    "            model.set_prob(256, 1/257)\n",
    "            model.normalize()\n",
    "            \n",
    "        t = 2**16 ## New lines!\n",
    "        l = int(model.get_low(symbol[0])*2**16)\n",
    "        h = int(model.get_high(symbol[0])*2**16)\n",
    "        enc.storeRegion(l,h,t) \n",
    "        \n",
    "        if idx < 100065: # back up before LSTM model\n",
    "            model.prob_list[symbol[0]] += 1/257\n",
    "            model.normalize()\n",
    "    t = 2**16 ## New lines!\n",
    "    l = int(model.get_low(256)*2**16)\n",
    "    h = int(model.get_high(256)*2**16)\n",
    "    enc.storeRegion(l,h,t)\n",
    "    enc.finish_encode(bitout)  # New line!\n",
    "inputfile, outputfile = 'data\\ecoli\\Ecoli.txt', 'data\\ecoli\\Ecoli_RF64.txt'\n",
    "\n",
    "#Perform file compression\n",
    "with open(inputfile, \"rb\") as inp, \\\n",
    "        contextlib.closing(arith.BitOutputStream(open(outputfile, \"wb\"))) as bitout:\n",
    "    RF_Warmcompress(inp, bitout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_onehot = np.load('temp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 percent done\n"
     ]
    }
   ],
   "source": [
    "char_list = [97, 103, 99, 116]\n",
    "def RF_Warmcompress(inp, bitout):\n",
    "    initprobs= [1/257 for i in range(257)]\n",
    "    initprobs[256] = 1-sum(initprobs[:256])\n",
    "    model = ProbabilityList(initprobs) # For the first 200,000\n",
    "    enc = arith.ArithmeticCoder(32)\n",
    "    enc.start_encode(bitout) # New line!\n",
    "\n",
    "    idx = 0\n",
    "    while True:\n",
    "        symbol = inp.read(1)\n",
    "        if len(symbol) == 0:\n",
    "                break\n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "        ## Progress Evaluation ## only internal\n",
    "        if idx % (len(ecoli)//10) == 0:\n",
    "            print(str(10*idx//(len(ecoli)//10)) + ' percent done')\n",
    "            clear_output(wait = True)\n",
    "        if idx == 100007:\n",
    "            model = ProbabilityList(initprobs) # reset the model\n",
    "        if idx >= 100007:\n",
    "            for val, prob in enumerate(predicted_onehot[idx-100007]):\n",
    "                model.set_prob(char_list[val], prob+1/257)\n",
    "            model.set_prob(256, 1/257)\n",
    "            model.normalize()\n",
    "            \n",
    "        t = 2**16 ## New lines!\n",
    "        l = int(model.get_low(symbol[0])*2**16)\n",
    "        h = int(model.get_high(symbol[0])*2**16)\n",
    "        enc.storeRegion(l,h,t) \n",
    "        \n",
    "        if idx < 100007: # back up before LSTM model\n",
    "            model.prob_list[symbol[0]] += 1/257\n",
    "            model.normalize()\n",
    "    t = 2**16 ## New lines!\n",
    "    l = int(model.get_low(256)*2**16)\n",
    "    h = int(model.get_high(256)*2**16)\n",
    "    enc.storeRegion(l,h,t)\n",
    "    enc.finish_encode(bitout)  # New line!\n",
    "inputfile, outputfile = 'data\\ecoli\\Ecoli.txt', 'data\\ecoli\\Ecoli_RF6_.txt'\n",
    "\n",
    "#Perform file compression\n",
    "with open(inputfile, \"rb\") as inp, \\\n",
    "        contextlib.closing(arith.BitOutputStream(open(outputfile, \"wb\"))) as bitout:\n",
    "    RF_Warmcompress(inp, bitout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
